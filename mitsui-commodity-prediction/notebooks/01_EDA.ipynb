{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 探索的データ分析 (EDA) - 三井物産商品価格予測チャレンジ\n",
    "\n",
    "このノートブックでは、コンペティションデータの詳細な探索と分析を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "try:\n",
    "    train = pd.read_csv('../data/raw/train.csv')\n",
    "    test = pd.read_csv('../data/raw/test.csv')\n",
    "    sample_submission = pd.read_csv('../data/raw/sample_submission.csv')\n",
    "    print(\"✅ データを正常に読み込みました\")\n",
    "except FileNotFoundError:\n",
    "    print(\"⚠️ データファイルが見つかりません。\")\n",
    "    print(\"Kaggle APIを使用してデータをダウンロードしてください：\")\n",
    "    print(\"!kaggle competitions download -c mitsui-commodity-prediction-challenge\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. データの基本情報"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"データセットの形状\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"訓練データ: {train.shape}\")\n",
    "print(f\"テストデータ: {test.shape}\")\n",
    "print(f\"サンプル提出: {sample_submission.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"データ型\")\n",
    "print(\"=\" * 50)\n",
    "print(train.dtypes.value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"訓練データの最初の5行\")\n",
    "print(\"=\" * 50)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 欠損値の分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_missing_values(df, title):\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = 100 * missing / len(df)\n",
    "    missing_table = pd.DataFrame({\n",
    "        'Missing_Count': missing,\n",
    "        'Missing_Percentage': missing_pct\n",
    "    })\n",
    "    missing_table = missing_table[missing_table['Missing_Count'] > 0].sort_values('Missing_Percentage', ascending=False)\n",
    "    \n",
    "    if len(missing_table) > 0:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        missing_table['Missing_Percentage'].plot(kind='barh')\n",
    "        plt.title(f'{title} - 欠損値の割合')\n",
    "        plt.xlabel('欠損値の割合 (%)')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.heatmap(df.isnull(), cbar=True, yticklabels=False, cmap='viridis')\n",
    "        plt.title(f'{title} - 欠損値パターン')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"✅ {title}に欠損値はありません\")\n",
    "    \n",
    "    return missing_table\n",
    "\n",
    "missing_train = analyze_missing_values(train, '訓練データ')\n",
    "missing_test = analyze_missing_values(test, 'テストデータ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 統計的要約"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"訓練データの統計的要約\")\n",
    "print(\"=\" * 80)\n",
    "train.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ターゲット変数の分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'target' in train.columns:\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('ターゲット分布', 'ボックスプロット', 'Q-Qプロット', '時系列')\n",
    "    )\n",
    "    \n",
    "    # ヒストグラム\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=train['target'], nbinsx=50, name='Target'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # ボックスプロット\n",
    "    fig.add_trace(\n",
    "        go.Box(y=train['target'], name='Target'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Q-Qプロット用データ準備\n",
    "    from scipy import stats\n",
    "    theoretical_quantiles = stats.probplot(train['target'], dist=\"norm\")[0][0]\n",
    "    sample_quantiles = stats.probplot(train['target'], dist=\"norm\")[0][1]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=theoretical_quantiles, y=sample_quantiles, mode='markers', name='Q-Q'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 時系列（もし日付カラムがある場合）\n",
    "    if 'date' in train.columns:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=train['date'], y=train['target'], mode='lines', name='Time Series'),\n",
    "            row=2, col=2\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(height=800, showlegend=False, title_text=\"ターゲット変数の詳細分析\")\n",
    "    fig.show()\n",
    "    \n",
    "    # 統計情報\n",
    "    print(\"ターゲット変数の統計:\")\n",
    "    print(f\"平均値: {train['target'].mean():.4f}\")\n",
    "    print(f\"中央値: {train['target'].median():.4f}\")\n",
    "    print(f\"標準偏差: {train['target'].std():.4f}\")\n",
    "    print(f\"歪度: {train['target'].skew():.4f}\")\n",
    "    print(f\"尖度: {train['target'].kurtosis():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 特徴量の相関分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数値型の特徴量のみ選択\n",
    "numeric_features = train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "if len(numeric_features) > 1:\n",
    "    # 相関行列の計算\n",
    "    correlation_matrix = train[numeric_features].corr()\n",
    "    \n",
    "    # ヒートマップ\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "    sns.heatmap(correlation_matrix, mask=mask, annot=True, fmt='.2f', \n",
    "                cmap='coolwarm', vmin=-1, vmax=1, center=0,\n",
    "                square=True, linewidths=0.5)\n",
    "    plt.title('特徴量の相関行列', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ターゲットとの相関が高い特徴量\n",
    "    if 'target' in train.columns:\n",
    "        target_corr = correlation_matrix['target'].sort_values(ascending=False)\n",
    "        print(\"\\nターゲットとの相関 (Top 10):\")\n",
    "        print(target_corr.head(11)[1:])  # targetを除く"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. カテゴリカル変数の分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "if categorical_features:\n",
    "    print(f\"カテゴリカル特徴量: {categorical_features}\")\n",
    "    \n",
    "    for col in categorical_features[:5]:  # 最初の5つのみ表示\n",
    "        print(f\"\\n{col}の値の分布:\")\n",
    "        print(train[col].value_counts().head(10))\n",
    "        \n",
    "        # カテゴリ数が少ない場合はプロット\n",
    "        if train[col].nunique() <= 20:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            train[col].value_counts().plot(kind='bar')\n",
    "            plt.title(f'{col}の分布')\n",
    "            plt.xlabel(col)\n",
    "            plt.ylabel('カウント')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "else:\n",
    "    print(\"カテゴリカル特徴量はありません\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 時系列分析（日付カラムがある場合）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'date' in train.columns:\n",
    "    # 日付型に変換\n",
    "    train['date'] = pd.to_datetime(train['date'])\n",
    "    test['date'] = pd.to_datetime(test['date']) if 'date' in test.columns else None\n",
    "    \n",
    "    # 時系列の範囲\n",
    "    print(f\"訓練データの期間: {train['date'].min()} から {train['date'].max()}\")\n",
    "    if 'date' in test.columns:\n",
    "        print(f\"テストデータの期間: {test['date'].min()} から {test['date'].max()}\")\n",
    "    \n",
    "    # 時系列でのデータポイント数\n",
    "    train_daily = train.groupby('date').size()\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(train_daily.index, train_daily.values)\n",
    "    plt.title('日次データポイント数')\n",
    "    plt.xlabel('日付')\n",
    "    plt.ylabel('データポイント数')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 曜日・月による分析\n",
    "    train['dayofweek'] = train['date'].dt.dayofweek\n",
    "    train['month'] = train['date'].dt.month\n",
    "    train['year'] = train['date'].dt.year\n",
    "    \n",
    "    if 'target' in train.columns:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "        \n",
    "        # 曜日別\n",
    "        train.groupby('dayofweek')['target'].mean().plot(kind='bar', ax=axes[0])\n",
    "        axes[0].set_title('曜日別平均ターゲット')\n",
    "        axes[0].set_xlabel('曜日 (0=月曜日)')\n",
    "        \n",
    "        # 月別\n",
    "        train.groupby('month')['target'].mean().plot(kind='bar', ax=axes[1])\n",
    "        axes[1].set_title('月別平均ターゲット')\n",
    "        axes[1].set_xlabel('月')\n",
    "        \n",
    "        # 年別\n",
    "        train.groupby('year')['target'].mean().plot(kind='bar', ax=axes[2])\n",
    "        axes[2].set_title('年別平均ターゲット')\n",
    "        axes[2].set_xlabel('年')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 外れ値の検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(df, features, n_std=3):\n",
    "    outliers_dict = {}\n",
    "    \n",
    "    for col in features:\n",
    "        if df[col].dtype in [np.int64, np.float64]:\n",
    "            mean = df[col].mean()\n",
    "            std = df[col].std()\n",
    "            \n",
    "            # Z-scoreを使用した外れ値検出\n",
    "            z_scores = np.abs((df[col] - mean) / std)\n",
    "            outliers = df[z_scores > n_std]\n",
    "            \n",
    "            if len(outliers) > 0:\n",
    "                outliers_dict[col] = len(outliers)\n",
    "    \n",
    "    return outliers_dict\n",
    "\n",
    "# 外れ値の検出\n",
    "outliers = detect_outliers(train, numeric_features)\n",
    "\n",
    "if outliers:\n",
    "    outliers_df = pd.DataFrame(list(outliers.items()), columns=['Feature', 'Outlier_Count'])\n",
    "    outliers_df['Outlier_Percentage'] = 100 * outliers_df['Outlier_Count'] / len(train)\n",
    "    outliers_df = outliers_df.sort_values('Outlier_Percentage', ascending=False)\n",
    "    \n",
    "    print(\"外れ値の検出結果 (3σ基準):\")\n",
    "    print(outliers_df)\n",
    "    \n",
    "    # 可視化\n",
    "    if len(outliers_df) > 0:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.bar(range(len(outliers_df)), outliers_df['Outlier_Percentage'])\n",
    "        plt.xticks(range(len(outliers_df)), outliers_df['Feature'], rotation=45)\n",
    "        plt.title('特徴量別外れ値の割合')\n",
    "        plt.ylabel('外れ値の割合 (%)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"外れ値は検出されませんでした（3σ基準）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. まとめと次のステップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"EDA サマリー\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n📊 データセット情報:\")\n",
    "print(f\"  - 訓練サンプル数: {len(train):,}\")\n",
    "print(f\"  - テストサンプル数: {len(test):,}\")\n",
    "print(f\"  - 特徴量数: {train.shape[1]}\")\n",
    "print(f\"  - 数値型特徴量: {len(numeric_features)}\")\n",
    "print(f\"  - カテゴリカル特徴量: {len(categorical_features)}\")\n",
    "\n",
    "if len(missing_train) > 0:\n",
    "    print(f\"\\n⚠️ 欠損値:\")\n",
    "    print(f\"  - 欠損値を含む特徴量数: {len(missing_train)}\")\n",
    "    print(f\"  - 最大欠損率: {missing_train['Missing_Percentage'].max():.2f}%\")\n",
    "\n",
    "if 'target' in train.columns:\n",
    "    print(f\"\\n🎯 ターゲット変数:\")\n",
    "    print(f\"  - 平均: {train['target'].mean():.4f}\")\n",
    "    print(f\"  - 標準偏差: {train['target'].std():.4f}\")\n",
    "    print(f\"  - 歪度: {train['target'].skew():.4f}\")\n",
    "\n",
    "print(f\"\\n📝 推奨される次のステップ:\")\n",
    "print(\"  1. 特徴量エンジニアリング\")\n",
    "print(\"  2. 欠損値の処理戦略の決定\")\n",
    "print(\"  3. 外れ値の処理\")\n",
    "print(\"  4. ベースラインモデルの構築\")\n",
    "print(\"  5. クロスバリデーション戦略の設計\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}