{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æ (EDA) - ä¸‰äº•ç‰©ç”£å•†å“ä¾¡æ ¼äºˆæ¸¬ãƒãƒ£ãƒ¬ãƒ³ã‚¸\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ãªæ¢ç´¢ã¨åˆ†æã‚’è¡Œã„ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\n",
    "try:\n",
    "    train = pd.read_csv('../data/raw/train.csv')\n",
    "    test = pd.read_csv('../data/raw/test.csv')\n",
    "    sample_submission = pd.read_csv('../data/raw/sample_submission.csv')\n",
    "    print(\"âœ… ãƒ‡ãƒ¼ã‚¿ã‚’æ­£å¸¸ã«èª­ã¿è¾¼ã¿ã¾ã—ãŸ\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "    print(\"Kaggle APIã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼š\")\n",
    "    print(\"!kaggle competitions download -c mitsui-commodity-prediction-challenge\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬æƒ…å ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å½¢çŠ¶\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {train.shape}\")\n",
    "print(f\"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {test.shape}\")\n",
    "print(f\"ã‚µãƒ³ãƒ—ãƒ«æå‡º: {sample_submission.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ãƒ‡ãƒ¼ã‚¿å‹\")\n",
    "print(\"=\" * 50)\n",
    "print(train.dtypes.value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æœ€åˆã®5è¡Œ\")\n",
    "print(\"=\" * 50)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. æ¬ æå€¤ã®åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_missing_values(df, title):\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = 100 * missing / len(df)\n",
    "    missing_table = pd.DataFrame({\n",
    "        'Missing_Count': missing,\n",
    "        'Missing_Percentage': missing_pct\n",
    "    })\n",
    "    missing_table = missing_table[missing_table['Missing_Count'] > 0].sort_values('Missing_Percentage', ascending=False)\n",
    "    \n",
    "    if len(missing_table) > 0:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        missing_table['Missing_Percentage'].plot(kind='barh')\n",
    "        plt.title(f'{title} - æ¬ æå€¤ã®å‰²åˆ')\n",
    "        plt.xlabel('æ¬ æå€¤ã®å‰²åˆ (%)')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.heatmap(df.isnull(), cbar=True, yticklabels=False, cmap='viridis')\n",
    "        plt.title(f'{title} - æ¬ æå€¤ãƒ‘ã‚¿ãƒ¼ãƒ³')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"âœ… {title}ã«æ¬ æå€¤ã¯ã‚ã‚Šã¾ã›ã‚“\")\n",
    "    \n",
    "    return missing_table\n",
    "\n",
    "missing_train = analyze_missing_values(train, 'è¨“ç·´ãƒ‡ãƒ¼ã‚¿')\n",
    "missing_test = analyze_missing_values(test, 'ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. çµ±è¨ˆçš„è¦ç´„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆçš„è¦ç´„\")\n",
    "print(\"=\" * 80)\n",
    "train.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã®åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'target' in train.columns:\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†å¸ƒ', 'ãƒœãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ', 'Q-Qãƒ—ãƒ­ãƒƒãƒˆ', 'æ™‚ç³»åˆ—')\n",
    "    )\n",
    "    \n",
    "    # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ \n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=train['target'], nbinsx=50, name='Target'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # ãƒœãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "    fig.add_trace(\n",
    "        go.Box(y=train['target'], name='Target'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Q-Qãƒ—ãƒ­ãƒƒãƒˆç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™\n",
    "    from scipy import stats\n",
    "    theoretical_quantiles = stats.probplot(train['target'], dist=\"norm\")[0][0]\n",
    "    sample_quantiles = stats.probplot(train['target'], dist=\"norm\")[0][1]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=theoretical_quantiles, y=sample_quantiles, mode='markers', name='Q-Q'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # æ™‚ç³»åˆ—ï¼ˆã‚‚ã—æ—¥ä»˜ã‚«ãƒ©ãƒ ãŒã‚ã‚‹å ´åˆï¼‰\n",
    "    if 'date' in train.columns:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=train['date'], y=train['target'], mode='lines', name='Time Series'),\n",
    "            row=2, col=2\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(height=800, showlegend=False, title_text=\"ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã®è©³ç´°åˆ†æ\")\n",
    "    fig.show()\n",
    "    \n",
    "    # çµ±è¨ˆæƒ…å ±\n",
    "    print(\"ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã®çµ±è¨ˆ:\")\n",
    "    print(f\"å¹³å‡å€¤: {train['target'].mean():.4f}\")\n",
    "    print(f\"ä¸­å¤®å€¤: {train['target'].median():.4f}\")\n",
    "    print(f\"æ¨™æº–åå·®: {train['target'].std():.4f}\")\n",
    "    print(f\"æ­ªåº¦: {train['target'].skew():.4f}\")\n",
    "    print(f\"å°–åº¦: {train['target'].kurtosis():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ç‰¹å¾´é‡ã®ç›¸é–¢åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°å€¤å‹ã®ç‰¹å¾´é‡ã®ã¿é¸æŠ\n",
    "numeric_features = train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "if len(numeric_features) > 1:\n",
    "    # ç›¸é–¢è¡Œåˆ—ã®è¨ˆç®—\n",
    "    correlation_matrix = train[numeric_features].corr()\n",
    "    \n",
    "    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "    sns.heatmap(correlation_matrix, mask=mask, annot=True, fmt='.2f', \n",
    "                cmap='coolwarm', vmin=-1, vmax=1, center=0,\n",
    "                square=True, linewidths=0.5)\n",
    "    plt.title('ç‰¹å¾´é‡ã®ç›¸é–¢è¡Œåˆ—', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã®ç›¸é–¢ãŒé«˜ã„ç‰¹å¾´é‡\n",
    "    if 'target' in train.columns:\n",
    "        target_corr = correlation_matrix['target'].sort_values(ascending=False)\n",
    "        print(\"\\nã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã®ç›¸é–¢ (Top 10):\")\n",
    "        print(target_corr.head(11)[1:])  # targetã‚’é™¤ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "if categorical_features:\n",
    "    print(f\"ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡: {categorical_features}\")\n",
    "    \n",
    "    for col in categorical_features[:5]:  # æœ€åˆã®5ã¤ã®ã¿è¡¨ç¤º\n",
    "        print(f\"\\n{col}ã®å€¤ã®åˆ†å¸ƒ:\")\n",
    "        print(train[col].value_counts().head(10))\n",
    "        \n",
    "        # ã‚«ãƒ†ã‚´ãƒªæ•°ãŒå°‘ãªã„å ´åˆã¯ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "        if train[col].nunique() <= 20:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            train[col].value_counts().plot(kind='bar')\n",
    "            plt.title(f'{col}ã®åˆ†å¸ƒ')\n",
    "            plt.xlabel(col)\n",
    "            plt.ylabel('ã‚«ã‚¦ãƒ³ãƒˆ')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "else:\n",
    "    print(\"ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ã¯ã‚ã‚Šã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. æ™‚ç³»åˆ—åˆ†æï¼ˆæ—¥ä»˜ã‚«ãƒ©ãƒ ãŒã‚ã‚‹å ´åˆï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'date' in train.columns:\n",
    "    # æ—¥ä»˜å‹ã«å¤‰æ›\n",
    "    train['date'] = pd.to_datetime(train['date'])\n",
    "    test['date'] = pd.to_datetime(test['date']) if 'date' in test.columns else None\n",
    "    \n",
    "    # æ™‚ç³»åˆ—ã®ç¯„å›²\n",
    "    print(f\"è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æœŸé–“: {train['date'].min()} ã‹ã‚‰ {train['date'].max()}\")\n",
    "    if 'date' in test.columns:\n",
    "        print(f\"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æœŸé–“: {test['date'].min()} ã‹ã‚‰ {test['date'].max()}\")\n",
    "    \n",
    "    # æ™‚ç³»åˆ—ã§ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæ•°\n",
    "    train_daily = train.groupby('date').size()\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(train_daily.index, train_daily.values)\n",
    "    plt.title('æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæ•°')\n",
    "    plt.xlabel('æ—¥ä»˜')\n",
    "    plt.ylabel('ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæ•°')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # æ›œæ—¥ãƒ»æœˆã«ã‚ˆã‚‹åˆ†æ\n",
    "    train['dayofweek'] = train['date'].dt.dayofweek\n",
    "    train['month'] = train['date'].dt.month\n",
    "    train['year'] = train['date'].dt.year\n",
    "    \n",
    "    if 'target' in train.columns:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "        \n",
    "        # æ›œæ—¥åˆ¥\n",
    "        train.groupby('dayofweek')['target'].mean().plot(kind='bar', ax=axes[0])\n",
    "        axes[0].set_title('æ›œæ—¥åˆ¥å¹³å‡ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ')\n",
    "        axes[0].set_xlabel('æ›œæ—¥ (0=æœˆæ›œæ—¥)')\n",
    "        \n",
    "        # æœˆåˆ¥\n",
    "        train.groupby('month')['target'].mean().plot(kind='bar', ax=axes[1])\n",
    "        axes[1].set_title('æœˆåˆ¥å¹³å‡ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ')\n",
    "        axes[1].set_xlabel('æœˆ')\n",
    "        \n",
    "        # å¹´åˆ¥\n",
    "        train.groupby('year')['target'].mean().plot(kind='bar', ax=axes[2])\n",
    "        axes[2].set_title('å¹´åˆ¥å¹³å‡ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ')\n",
    "        axes[2].set_xlabel('å¹´')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. å¤–ã‚Œå€¤ã®æ¤œå‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(df, features, n_std=3):\n",
    "    outliers_dict = {}\n",
    "    \n",
    "    for col in features:\n",
    "        if df[col].dtype in [np.int64, np.float64]:\n",
    "            mean = df[col].mean()\n",
    "            std = df[col].std()\n",
    "            \n",
    "            # Z-scoreã‚’ä½¿ç”¨ã—ãŸå¤–ã‚Œå€¤æ¤œå‡º\n",
    "            z_scores = np.abs((df[col] - mean) / std)\n",
    "            outliers = df[z_scores > n_std]\n",
    "            \n",
    "            if len(outliers) > 0:\n",
    "                outliers_dict[col] = len(outliers)\n",
    "    \n",
    "    return outliers_dict\n",
    "\n",
    "# å¤–ã‚Œå€¤ã®æ¤œå‡º\n",
    "outliers = detect_outliers(train, numeric_features)\n",
    "\n",
    "if outliers:\n",
    "    outliers_df = pd.DataFrame(list(outliers.items()), columns=['Feature', 'Outlier_Count'])\n",
    "    outliers_df['Outlier_Percentage'] = 100 * outliers_df['Outlier_Count'] / len(train)\n",
    "    outliers_df = outliers_df.sort_values('Outlier_Percentage', ascending=False)\n",
    "    \n",
    "    print(\"å¤–ã‚Œå€¤ã®æ¤œå‡ºçµæœ (3ÏƒåŸºæº–):\")\n",
    "    print(outliers_df)\n",
    "    \n",
    "    # å¯è¦–åŒ–\n",
    "    if len(outliers_df) > 0:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.bar(range(len(outliers_df)), outliers_df['Outlier_Percentage'])\n",
    "        plt.xticks(range(len(outliers_df)), outliers_df['Feature'], rotation=45)\n",
    "        plt.title('ç‰¹å¾´é‡åˆ¥å¤–ã‚Œå€¤ã®å‰²åˆ')\n",
    "        plt.ylabel('å¤–ã‚Œå€¤ã®å‰²åˆ (%)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"å¤–ã‚Œå€¤ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼ˆ3ÏƒåŸºæº–ï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ã¾ã¨ã‚ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"EDA ã‚µãƒãƒªãƒ¼\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±:\")\n",
    "print(f\"  - è¨“ç·´ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(train):,}\")\n",
    "print(f\"  - ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«æ•°: {len(test):,}\")\n",
    "print(f\"  - ç‰¹å¾´é‡æ•°: {train.shape[1]}\")\n",
    "print(f\"  - æ•°å€¤å‹ç‰¹å¾´é‡: {len(numeric_features)}\")\n",
    "print(f\"  - ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡: {len(categorical_features)}\")\n",
    "\n",
    "if len(missing_train) > 0:\n",
    "    print(f\"\\nâš ï¸ æ¬ æå€¤:\")\n",
    "    print(f\"  - æ¬ æå€¤ã‚’å«ã‚€ç‰¹å¾´é‡æ•°: {len(missing_train)}\")\n",
    "    print(f\"  - æœ€å¤§æ¬ æç‡: {missing_train['Missing_Percentage'].max():.2f}%\")\n",
    "\n",
    "if 'target' in train.columns:\n",
    "    print(f\"\\nğŸ¯ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°:\")\n",
    "    print(f\"  - å¹³å‡: {train['target'].mean():.4f}\")\n",
    "    print(f\"  - æ¨™æº–åå·®: {train['target'].std():.4f}\")\n",
    "    print(f\"  - æ­ªåº¦: {train['target'].skew():.4f}\")\n",
    "\n",
    "print(f\"\\nğŸ“ æ¨å¥¨ã•ã‚Œã‚‹æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:\")\n",
    "print(\"  1. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°\")\n",
    "print(\"  2. æ¬ æå€¤ã®å‡¦ç†æˆ¦ç•¥ã®æ±ºå®š\")\n",
    "print(\"  3. å¤–ã‚Œå€¤ã®å‡¦ç†\")\n",
    "print(\"  4. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰\")\n",
    "print(\"  5. ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æˆ¦ç•¥ã®è¨­è¨ˆ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}